{"version":3,"sources":["index.js","lib/types/raw.js","lib/read.js"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;AACA,ACHA;ADIA,ACHA;ADIA,ACHA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA,ADGA;ADIA,AENA;AFOA,AENA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["/*!\n * body-parser\n * Copyright(c) 2014-2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n\n\n/**\n * @typedef Parsers\n * @type {function}\n * @property {function} json\n * @property {function} raw\n * @property {function} text\n * @property {function} urlencoded\n */\n\n/**\n * Module exports.\n * @type {Parsers}\n */\n\nexports = module.exports = bodyParser\n\n/**\n * JSON parser.\n * @public\n */\n\nObject.defineProperty(exports, 'json', {\n  configurable: true,\n  enumerable: true,\n  get: () => require('./lib/types/json')\n})\n\n/**\n * Raw parser.\n * @public\n */\n\nObject.defineProperty(exports, 'raw', {\n  configurable: true,\n  enumerable: true,\n  get: () => require('./lib/types/raw')\n})\n\n/**\n * Text parser.\n * @public\n */\n\nObject.defineProperty(exports, 'text', {\n  configurable: true,\n  enumerable: true,\n  get: () => require('./lib/types/text')\n})\n\n/**\n * URL-encoded parser.\n * @public\n */\n\nObject.defineProperty(exports, 'urlencoded', {\n  configurable: true,\n  enumerable: true,\n  get: () => require('./lib/types/urlencoded')\n})\n\n/**\n * Create a middleware to parse json and urlencoded bodies.\n *\n * @param {object} [options]\n * @return {function}\n * @deprecated\n * @public\n */\n\nfunction bodyParser () {\n  throw new Error('The bodyParser() generic has been split into individual middleware to use instead.')\n}\n","/*!\n * body-parser\n * Copyright(c) 2014-2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n\n\n/**\n * Module dependencies.\n */\n\nvar debug = require('debug')('body-parser:raw')\nvar isFinished = require('on-finished').isFinished\nvar read = require('../read')\nvar typeis = require('type-is')\nvar { normalizeOptions } = require('../utils')\n\n/**\n * Module exports.\n */\n\nmodule.exports = raw\n\n/**\n * Create a middleware to parse raw bodies.\n *\n * @param {object} [options]\n * @return {function}\n * @api public\n */\n\nfunction raw (options) {\n  var { inflate, limit, verify, shouldParse } = normalizeOptions(options, 'application/octet-stream')\n\n  function parse (buf) {\n    return buf\n  }\n\n  return function rawParser (req, res, next) {\n    if (isFinished(req)) {\n      debug('body already parsed')\n      next()\n      return\n    }\n\n    if (!('body' in req)) {\n      req.body = undefined\n    }\n\n    // skip requests without bodies\n    if (!typeis.hasBody(req)) {\n      debug('skip empty body')\n      next()\n      return\n    }\n\n    debug('content-type %j', req.headers['content-type'])\n\n    // determine if request should be parsed\n    if (!shouldParse(req)) {\n      debug('skip parsing')\n      next()\n      return\n    }\n\n    // read\n    read(req, res, next, parse, debug, {\n      encoding: null,\n      inflate,\n      limit,\n      verify\n    })\n  }\n}\n","/*!\n * body-parser\n * Copyright(c) 2014-2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar createError = require('http-errors')\nvar getBody = require('raw-body')\nvar iconv = require('iconv-lite')\nvar onFinished = require('on-finished')\nvar zlib = require('node:zlib')\n\n/**\n * Module exports.\n */\n\nmodule.exports = read\n\n/**\n * Read a request into a buffer and parse.\n *\n * @param {object} req\n * @param {object} res\n * @param {function} next\n * @param {function} parse\n * @param {function} debug\n * @param {object} options\n * @private\n */\n\nfunction read (req, res, next, parse, debug, options) {\n  var length\n  var opts = options\n  var stream\n\n  // read options\n  var encoding = opts.encoding !== null\n    ? opts.encoding\n    : null\n  var verify = opts.verify\n\n  try {\n    // get the content stream\n    stream = contentstream(req, debug, opts.inflate)\n    length = stream.length\n    stream.length = undefined\n  } catch (err) {\n    return next(err)\n  }\n\n  // set raw-body options\n  opts.length = length\n  opts.encoding = verify\n    ? null\n    : encoding\n\n  // assert charset is supported\n  if (opts.encoding === null && encoding !== null && !iconv.encodingExists(encoding)) {\n    return next(createError(415, 'unsupported charset \"' + encoding.toUpperCase() + '\"', {\n      charset: encoding.toLowerCase(),\n      type: 'charset.unsupported'\n    }))\n  }\n\n  // read body\n  debug('read body')\n  getBody(stream, opts, function (error, body) {\n    if (error) {\n      var _error\n\n      if (error.type === 'encoding.unsupported') {\n        // echo back charset\n        _error = createError(415, 'unsupported charset \"' + encoding.toUpperCase() + '\"', {\n          charset: encoding.toLowerCase(),\n          type: 'charset.unsupported'\n        })\n      } else {\n        // set status code on error\n        _error = createError(400, error)\n      }\n\n      // unpipe from stream and destroy\n      if (stream !== req) {\n        req.unpipe()\n        stream.destroy()\n      }\n\n      // read off entire request\n      dump(req, function onfinished () {\n        next(createError(400, _error))\n      })\n      return\n    }\n\n    // verify\n    if (verify) {\n      try {\n        debug('verify body')\n        verify(req, res, body, encoding)\n      } catch (err) {\n        next(createError(403, err, {\n          body: body,\n          type: err.type || 'entity.verify.failed'\n        }))\n        return\n      }\n    }\n\n    // parse\n    var str = body\n    try {\n      debug('parse body')\n      str = typeof body !== 'string' && encoding !== null\n        ? iconv.decode(body, encoding)\n        : body\n      req.body = parse(str, encoding)\n    } catch (err) {\n      next(createError(400, err, {\n        body: str,\n        type: err.type || 'entity.parse.failed'\n      }))\n      return\n    }\n\n    next()\n  })\n}\n\n/**\n * Get the content stream of the request.\n *\n * @param {object} req\n * @param {function} debug\n * @param {boolean} [inflate=true]\n * @return {object}\n * @api private\n */\n\nfunction contentstream (req, debug, inflate) {\n  var encoding = (req.headers['content-encoding'] || 'identity').toLowerCase()\n  var length = req.headers['content-length']\n\n  debug('content-encoding \"%s\"', encoding)\n\n  if (inflate === false && encoding !== 'identity') {\n    throw createError(415, 'content encoding unsupported', {\n      encoding: encoding,\n      type: 'encoding.unsupported'\n    })\n  }\n\n  if (encoding === 'identity') {\n    req.length = length\n    return req\n  }\n\n  var stream = createDecompressionStream(encoding, debug)\n  req.pipe(stream)\n  return stream\n}\n\n/**\n * Create a decompression stream for the given encoding.\n * @param {string} encoding\n * @param {function} debug\n * @return {object}\n * @api private\n */\nfunction createDecompressionStream (encoding, debug) {\n  switch (encoding) {\n    case 'deflate':\n      debug('inflate body')\n      return zlib.createInflate()\n    case 'gzip':\n      debug('gunzip body')\n      return zlib.createGunzip()\n    case 'br':\n      debug('brotli decompress body')\n      return zlib.createBrotliDecompress()\n    default:\n      throw createError(415, 'unsupported content encoding \"' + encoding + '\"', {\n        encoding: encoding,\n        type: 'encoding.unsupported'\n      })\n  }\n}\n\n/**\n * Dump the contents of a request.\n *\n * @param {object} req\n * @param {function} callback\n * @api private\n */\n\nfunction dump (req, callback) {\n  if (onFinished.isFinished(req)) {\n    callback(null)\n  } else {\n    onFinished(req, callback)\n    req.resume()\n  }\n}\n"]}